{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chord Recognizer.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5Bos4SN0Qqs",
        "colab_type": "text"
      },
      "source": [
        "# Initializaton"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uz1rIkDrR-DM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# System\n",
        "import os\n",
        "from pathlib import Path\n",
        "import random\n",
        "from shutil import copyfile\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Sound\n",
        "import librosa\n",
        "\n",
        "# AI\n",
        "import fastai\n",
        "from fastai.vision import *\n",
        "\n",
        "# Visual\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Audio,display\n",
        "import librosa.display\n",
        "\n",
        "#from itertools import islice\n",
        "#from scipy.fftpack import fft\n",
        "#import mir_eval\n",
        "#from scipy.signal import get_window\n",
        "#import json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y74peUyASKNV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EEKBs1zXbfwn",
        "colab_type": "text"
      },
      "source": [
        "# Global variables and functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZyfEIv9WSMoR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ROOT = Path('/content/drive/My Drive/Colab Notebooks/Chord Recognizer')\n",
        "\n",
        "CHORD_SPECIFICTS = { \n",
        "  'Am': [0,2,2,1,0],\n",
        "  'G' : [3,2,0,0,3,3],\n",
        "  'A' : [0,2,2,2,0],\n",
        "  'C' : [3,2,0,1,0],\n",
        "  'D' : [0,2,3,2],\n",
        "  'Dm': [0,2,3,1],\n",
        "  'E' : [0,2,2,1,0,0],\n",
        "  'F' : [1,3,3,2,1,1],\n",
        "  'H7': [0,2,1,2,0,2],\n",
        "  'Em': [0,2,2,0,0,0]\n",
        "}\n",
        "\n",
        "SR = 16000\n",
        "N_FFT = 1000\n",
        "HOP_LENGHT = 250\n",
        "N_MELS = 64\n",
        "F_MIN = 20\n",
        "F_MAX = 2000\n",
        "IMG_SIZE=64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZ66E2HmUxBa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Ploting\n",
        "def plot_signal(signal, sr, figsize=(12,3), title = None):\n",
        "  plt.figure(figsize=figsize)\n",
        "  librosa.display.waveplot(signal,sr=sr)\n",
        "  plt.xlabel('Time (s)')\n",
        "  plt.ylabel('Magnitude')\n",
        "  plt.title(title)\n",
        "  plt.show()\n",
        "\n",
        "# Clip processing\n",
        "def get_chord_instances(clip, count, sr, bpm):\n",
        "  l = sr * 60 // bpm # chord instance length\n",
        "  return [clip[i*l:(i+1)*l] for i in range(0, count)]\n",
        "\n",
        "# Spectrograms\n",
        "def signal_to_log_mel_spec(signal, sr = SR):    \n",
        "    mel_spec = librosa.feature.melspectrogram(signal,\n",
        "                                              sr=sr,\n",
        "                                              n_fft=N_FFT, \n",
        "                                              hop_length=HOP_LENGHT, \n",
        "                                              n_mels=N_MELS,\n",
        "                                              power=1.0, \n",
        "                                              fmin=F_MIN,\n",
        "                                              fmax=F_MAX)\n",
        "    \n",
        "    return librosa.amplitude_to_db(mel_spec, ref=np.max)\n",
        "    \n",
        "def save_mel_spec(mel_spec, dst_path, fname):\n",
        "  dst_fname = dst_path / (fname + '.png')\n",
        "  plt.imsave(dst_fname, mel_spec)\n",
        "\n",
        "# Clips generation\n",
        "def who_can_play(pitches,\n",
        "                 bad = {2,4,6,7,8,10,11,12,13,15,16,19,20,23,24,25,27,28,30,32,35,36},\n",
        "                 data_path=ROOT/'structurized-nsynth'):\n",
        "  result = dict()\n",
        "  instrument_classes = os.listdir(data_path)\n",
        "  instrument_classes = [i for i in instrument_classes if int(i) not in bad]\n",
        "\n",
        "  for i in instrument_classes:\n",
        "    pitches_dict = dict()\n",
        "    for p in pitches:\n",
        "      pitch_dir = data_path/i/str(p)\n",
        "      if not os.path.exists(pitch_dir):\n",
        "        break\n",
        "      pitches_dict[p] = set([int(os.path.splitext(f)[0]) for f in os.listdir(pitch_dir)])\n",
        "    if len(pitches_dict) == len(pitches):\n",
        "      result[int(i)] = pitches_dict\n",
        "\n",
        "  return result \n",
        "\n",
        "def gen_chord(pitches_and_velocities,\n",
        "              instrument,\n",
        "              seconds=1.0,\n",
        "              sr = SR,\n",
        "              start_pad = 1200,\n",
        "              gaps=[320]*5,\n",
        "              data_path=ROOT/'structurized-nsynth'):\n",
        "\n",
        "  strings = [librosa.load(f,sr=None)[0]\n",
        "            for f in [data_path/'{}/{}/{}.wav'.format(instrument,p,v)\n",
        "               for (p,v) in pitches_and_velocities]]\n",
        "\n",
        "  result = np.zeros((sr * 4 + np.sum(gaps)))\n",
        "\n",
        "  for i in range(len(strings)):\n",
        "    c = np.pad(strings[i], (np.sum(gaps[:i],dtype=int), np.sum(gaps[i:],dtype=int)), 'constant', constant_values=(0,0))\n",
        "    result = np.add(result,c)\n",
        "  result = np.pad(result, (start_pad, 0), 'constant',constant_values=(0,0))\n",
        "  return result[:int(sr*seconds)]\n",
        "\n",
        "\n",
        "def gen_some_chords(chord_class,\n",
        "                    count,\n",
        "                    seconds = 1.0,\n",
        "                    sr = SR,\n",
        "                    flip=False,\n",
        "                    pad_max  = 0.1875,\n",
        "                    gaps_min = 0.0125,\n",
        "                    gaps_max = 0.0375,\n",
        "                    dest_root=None,\n",
        "                    n_fft = None,\n",
        "                    hop_length = None,\n",
        "                    n_mels = None,\n",
        "                    save=False):\n",
        "  specs = CHORD_SPECIFICTS[chord_class]\n",
        "  standard = np.array([40,45,50,55,59,64])[-len(specs):]\n",
        "  pitches = standard + specs\n",
        "  \n",
        "  if flip:\n",
        "    pitches = np.flip(pitches)\n",
        "  \n",
        "  instruments = who_can_play(pitches)\n",
        "  instruments_classes = list(instruments)\n",
        "  instruments_classes.sort()\n",
        "  indicies = np.resize(instruments_classes,count)\n",
        "  \n",
        "  for c in range(count):\n",
        "    i = indicies[c]\n",
        "    pitches_and_velocities = [(p,random.choice(tuple(v))) for p,v in instruments[i].items() ]\n",
        "\n",
        "    gaps_count = len(pitches)-1\n",
        "    gaps_min_samples = int(sr*gaps_min)\n",
        "    gaps_max_samples = int(sr*gaps_max)\n",
        "    pad_max_samples  = int(sr*pad_max)\n",
        "    \n",
        "    gaps = [random.randint(gaps_min_samples,gaps_max_samples) for i in range(gaps_count)]\n",
        "    pad  = random.randint(0,pad_max_samples)\n",
        "    chord = gen_chord(pitches_and_velocities,i,start_pad=pad,gaps=gaps,seconds=seconds)\n",
        "\n",
        "    if save :\n",
        "      dest_dir = dest_root/chord_class\n",
        "      if not os.path.exists(dest_dir):\n",
        "        dest_dir.mkdir()\n",
        "      fname = '{}_{}'.format(len(os.listdir(dest_dir)),i)\n",
        "      mel_spec = signal_to_log_mel_spec(chord, SR)\n",
        "\n",
        "      save_mel_spec(mel_spec,dest_dir, fname)\n",
        "    else :\n",
        "      plot_signal(chord,SR,(12,1.5),title = i)\n",
        "      display(Audio(chord,rate=16000))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yL1FYVuKVxiZ",
        "colab_type": "text"
      },
      "source": [
        "# Recorded data sandbox"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-t1vDEA9f-Hn",
        "colab_type": "text"
      },
      "source": [
        "Goal of recorded data sandbox is to find appropriate start padding for recorded clip and to check visualy if the chord instance have appropriate shape."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzrG1ysqgchS",
        "colab_type": "text"
      },
      "source": [
        "In this case every chord recorded 60 times with sr = 48 kHz and bpm = 60. Padding approx. = 2s"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4c04R3_6V1xI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(ROOT/'recorded/data.csv')\n",
        "chord_classes = df['chord'].to_list()\n",
        "clips = [ librosa.load(ROOT/'recorded/audio'/'{}.mp4'.format(chord),sr=SR)[0] for chord in chord_classes ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48b9-j-0c1VK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#paddings = {'A':[1.8],'Am':[1.8],'C':[1.85],'D':[1.82],'Dm':[1.9],'E':[1.85],'Em':[1.8],'F':[1.8],'G':[1.8],'H7':[1.88]}\n",
        "paddings = { v['chord'] : v['pad']  for v in df.to_dict('index').values() }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XdfVvq4dVrT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Checked : A, Am, C, D, Dm, E, F, G, H7, Em\n",
        "\n",
        "i = 0\n",
        "clip = clips[i]\n",
        "chord_class = chord_classes[i]\n",
        "start_in_secs = paddings[chord_class]\n",
        "start = int(start_in_secs * SR)\n",
        "clip = clip[start:]\n",
        "\n",
        "chord_instances = get_chord_instances(clip, count=60, sr=SR, bpm=60)\n",
        "\n",
        "plot_signal(clip,sr=SR,figsize=(20,4),title=chord_class)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBb4g-8reKCu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for j in range(60):\n",
        "  chord_instance = chord_instances[j]\n",
        "  plot_signal(chord_instance,sr=SR,figsize=(6,1.5), title=j)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5FwU77Wg0Zq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "j = 14\n",
        "chord_instance = chord_instances[j]\n",
        "\n",
        "plot_signal(chord_instance,SR,(12,1.5),chord_class)\n",
        "Audio(chord_instance,rate=SR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdkaC8j0-Xsf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "librosa.output.write_wav(ROOT/'chord_instance.wav', chord_instance, SR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXhPZRVuhNcR",
        "colab_type": "text"
      },
      "source": [
        "# Recorded data to spectrograms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAavkEVcyK0F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(ROOT/'recorded/data.csv')\n",
        "REC_ROOT = ROOT/'recorded/spectrograms-64x64'\n",
        "\n",
        "chord_classes = df['chord'].to_list()\n",
        "clips = [ librosa.load(ROOT/'recorded/audio'/'{}.mp4'.format(chord),sr=SR)[0] for chord in chord_classes ]\n",
        "paddings = { v['chord'] : v['pad']  for v in df.to_dict('index').values() }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_mHDIcdyNRq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for chord_class in chord_classes:\n",
        "  chord_specs_path = REC_ROOT/chord_class\n",
        "  chord_specs_path.mkdir(parents=True, exist_ok=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsSO_3eohY_Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(clips)): \n",
        "  clip = clips[i]\n",
        "  chord_class = chord_classes[i]\n",
        "\n",
        "  start_in_secs = paddings[chord_class]\n",
        "  start = int(start_in_secs * SR)\n",
        "  clip = clip[start:]\n",
        "\n",
        "  chord_specs_path = REC_ROOT/chord_class\n",
        "  chord_instances = get_chord_instances(clip,60,SR,60)\n",
        "\n",
        "  for chord_instance in chord_instances:\n",
        "    fname = str(len(os.listdir(chord_specs_path)))\n",
        "    mel_spec = signal_to_log_mel_spec(chord_instance, SR)\n",
        "    save_mel_spec(mel_spec,chord_specs_path, fname)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gH0i4VK0DWe",
        "colab_type": "text"
      },
      "source": [
        "# Generate spectrograms\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ml70Gr34BAHL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#bad = [2,4,6-8,10-13,15-16,19-20,23-25,27-28,30,32,35-36]\n",
        "GEN_ROOT = ROOT/'generated/spectrograms-64x64'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFr1VA7X0Mhl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for c in CHORD_SPECIFICTS.keys():\n",
        "  print(c,datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\"))\n",
        "  gen_some_chords(c, 140, dest_root=GEN_ROOT,save=True)\n",
        "  print('Flip', c, datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\"))\n",
        "  gen_some_chords(c, 140, flip=True, dest_root=GEN_ROOT,save=True)\n",
        "print(\"END\",datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szjeKRrkIPoC",
        "colab_type": "text"
      },
      "source": [
        "# Mixing datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Zja505P7hxV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_bunch = ImageDataBunch.from_folder(ROOT/'recorded/spectrograms_generated-64x64',train=\".\",valid_pct=0.3,classes=classes)\n",
        "data_test = ImageDataBunch.from_folder(ROOT/'recorded/spectrograms-64x64',train=\".\",valid_pct=0.3,classes=classes)\n",
        "data_bunch.valid_dl = data_test.valid_dl\n",
        "data_test.valid_dl = data_test.train_dl\n",
        "data_test.test_dl = DeviceDataLoader.create({})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYAOaEoqW6xb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rec_train_pct = 0.25\n",
        "rec_valid_pct = 0.25\n",
        "gen_test_pct  = 0.3\n",
        "\n",
        "REC_COUNT_PER_CLASS = 60\n",
        "GEN_COUTN_PER_CLASS = 280\n",
        "\n",
        "GEN_ROOT = ROOT/'data/spectrograms_generated-64x64'\n",
        "REC_ROOT = ROOT/'data/spectrograms-64x64'\n",
        "\n",
        "for c in classes:\n",
        "  fnames = [\"%d.png\" % i for i in range(REC_COUNT_PER_CLASS)]\n",
        "  random.shuffle(fnames)\n",
        "  \n",
        "  train_count = int(REC_COUNT_PER_CLASS*rec_train_pct)\n",
        "  valid_count = int(REC_COUNT_PER_CLASS*rec_valid_pct)\n",
        "\n",
        "  train = fnames[: train_count]\n",
        "  valid = fnames[train_count : train_count+valid_count]\n",
        "  test = fnames[train_count+valid_count :]\n",
        "\n",
        "  for data, dirname in [(train,\"train\"),(valid,\"valid\"),(test,\"test\")]:\n",
        "    Path('tmp/recognizer/%s/%s' % (dirname, c)).mkdir(parents=True, exist_ok=True)\n",
        "    for fname in data: \n",
        "      copyfile(REC_ROOT/c/fname,\n",
        "      'tmp/recognizer/%s/%s/%s' % (dirname,c,fname))\n",
        "  \n",
        "  test_count = int(GEN_COUTN_PER_CLASS*gen_test_pct)\n",
        "  fnames = os.listdir(GEN_ROOT/c)\n",
        "  random.shuffle(fnames)\n",
        "  train = fnames[:test_count]\n",
        "\n",
        "  for fname in train: \n",
        "    copyfile(GEN_ROOT/c/fname,\n",
        "              'tmp/recognizer/train/%s/%s' % (c,fname))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SnhlJOrV7TzK"
      },
      "source": [
        "# Training\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QP6ZKpNlBR_f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classes=['A', 'Am', 'C', 'D', 'Dm', 'E', 'Em', 'F', 'G', 'H7' ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGr-DbnXkiUf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_bunch = ImageDataBunch.from_folder(ROOT/'data/spectrograms_generated-64x64', valid_pct=0, bs=32,size=IMG_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dv9sVgDHktHl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_bunch.show_batch(3)\n",
        "data_bunch.classes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Ia4aJg6kuxr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn = cnn_learner(data_bunch, models.resnet18, metrics=accuracy)\n",
        "learn.freeze()\n",
        "learn.fit_one_cycle(2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yd18ACLmlsJ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "interp = ClassificationInterpretation.from_learner(learn)\n",
        "interp.plot_confusion_matrix()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUVw_4JrlxlX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.unfreeze()\n",
        "learn.lr_find()\n",
        "learn.recorder.plot()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZM7qrzdNmE-u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.fit_one_cycle(3, max_lr=slice(5e-4, 5e-3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L62tkoJcmSN4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "interp = ClassificationInterpretation.from_learner(learn)\n",
        "interp.plot_confusion_matrix()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXRQeNsdwbPc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.validate(data_test.valid_dl,metrics=[accuracy])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YujnUg5L91B4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.save('13')\n",
        "learn.export()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTGERQLamkEZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_test = ImageDataBunch.from_folder('tmp/recognizer',train=\"train\",valid='test',bs=32)\n",
        "#data_test = ImageDataBunch.from_folder(ROOT/'recorded',train=\"spectrograms_generated-2000HZ\",valid='spectrograms-2000HZ',classes=classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Av3qHCHRu2wk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn = cnn_learner(data_test, models.resnet18, metrics=accuracy)\n",
        "learn.load(ROOT/'recorded/spectrograms_generated-2000HZ/models/13');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVwVbZS8q5Za",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.validate(data_test.valid_dl,metrics=[accuracy])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}